{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lane_detection.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMQM9mAmpKsa3egzaMB+5cW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dchatterjee/vision.lane-detection/blob/main/lane_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from scipy import optimize\n",
        "from matplotlib import pyplot as plt, cm, colors"
      ],
      "metadata": {
        "id": "-KTAQ1bK7L1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining variables to hold meter-to-pixel conversion\n",
        "ym_per_pix = 30 / 720\n",
        "# Standard lane width is 3.7 meters divided by lane width in pixels which is\n",
        "# calculated to be approximately 720 pixels not to be confused with frame height\n",
        "xm_per_pix = 3.7 / 720\n",
        "\n",
        "# Get path to the current working directory\n",
        "CWD_PATH = os.getcwd()"
      ],
      "metadata": {
        "id": "qR4-g0Dn7MbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "image_input_dir = os.getcwd()\n",
        "\n",
        "def upload_files(upload_path):\n",
        "  uploaded = files.upload()\n",
        "  for filename, content in uploaded.items():\n",
        "    dst_path = os.path.join(upload_path, filename)\n",
        "    shutil.move(filename, dst_path)\n",
        "  return list(uploaded.keys())"
      ],
      "metadata": {
        "id": "g8T5t0g-7U6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  uploaded_image_list = upload_files(image_input_dir)"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "F61v2FvA8gNk",
        "outputId": "3f4f8e22-1ef0-4367-e2b9-0600d14f6581"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-20fb2774-7662-48ef-a1bf-94730b37e032\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-20fb2774-7662-48ef-a1bf-94730b37e032\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving drive.mp4 to drive.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def readVideo():\n",
        "\n",
        "    # Read input video from current working directory\n",
        "    inpImage = cv2.VideoCapture(os.path.join(CWD_PATH, 'drive.mp4'))\n",
        "\n",
        "    return inpImage"
      ],
      "metadata": {
        "id": "O0oPKNpF7x35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def processImage(inpImage):\n",
        "\n",
        "    # Apply HLS color filtering to filter out white lane lines\n",
        "    hls = cv2.cvtColor(inpImage, cv2.COLOR_BGR2HLS)\n",
        "    lower_white = np.array([0, 160, 10])\n",
        "    upper_white = np.array([255, 255, 255])\n",
        "    mask = cv2.inRange(inpImage, lower_white, upper_white)\n",
        "    hls_result = cv2.bitwise_and(inpImage, inpImage, mask = mask)\n",
        "\n",
        "    # Convert image to grayscale, apply threshold, blur & extract edges\n",
        "    gray = cv2.cvtColor(hls_result, cv2.COLOR_BGR2GRAY)\n",
        "    ret, thresh = cv2.threshold(gray, 160, 255, cv2.THRESH_BINARY)\n",
        "    blur = cv2.GaussianBlur(thresh,(3, 3), 0)\n",
        "    canny = cv2.Canny(blur, 40, 60)\n",
        "\n",
        "    # Display the processed images\n",
        "##    cv2.imshow(\"Image\", inpImage)\n",
        "##    cv2.imshow(\"HLS Filtered\", hls_result)\n",
        "##    cv2.imshow(\"Grayscale\", gray)\n",
        "##    cv2.imshow(\"Thresholded\", thresh)\n",
        "##    cv2.imshow(\"Blurred\", blur)\n",
        "##    cv2.imshow(\"Canny Edges\", canny)\n",
        "\n",
        "    return image, hls_result, gray, thresh, blur, canny"
      ],
      "metadata": {
        "id": "a4tcy-eh9CyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perspectiveWarp(inpImage):\n",
        "\n",
        "    # Get image size\n",
        "    img_size = (inpImage.shape[1], inpImage.shape[0])\n",
        "\n",
        "    # Perspective points to be warped\n",
        "    src = np.float32([[590, 440],\n",
        "                      [690, 440],\n",
        "                      [200, 640],\n",
        "                      [1000, 640]])\n",
        "\n",
        "    # Window to be shown\n",
        "    dst = np.float32([[200, 0],\n",
        "                      [1200, 0],\n",
        "                      [200, 710],\n",
        "                      [1200, 710]])\n",
        "\n",
        "    # Matrix to warp the image for birdseye window\n",
        "    matrix = cv2.getPerspectiveTransform(src, dst)\n",
        "    # Inverse matrix to unwarp the image for final window\n",
        "    minv = cv2.getPerspectiveTransform(dst, src)\n",
        "    birdseye = cv2.warpPerspective(inpImage, matrix, img_size)\n",
        "\n",
        "    # Get the birdseye window dimensions\n",
        "    height, width = birdseye.shape[:2]\n",
        "\n",
        "    # Divide the birdseye view into 2 halves to separate left & right lanes\n",
        "    birdseyeLeft  = birdseye[0:height, 0:width // 2]\n",
        "    birdseyeRight = birdseye[0:height, width // 2:width]\n",
        "\n",
        "    # Display birdseye view image\n",
        "    # cv2.imshow(\"Birdseye\" , birdseye)\n",
        "    # cv2.imshow(\"Birdseye Left\" , birdseyeLeft)\n",
        "    # cv2.imshow(\"Birdseye Right\", birdseyeRight)\n",
        "\n",
        "    return birdseye, birdseyeLeft, birdseyeRight, minv"
      ],
      "metadata": {
        "id": "nWD36DR-9D3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plotHistogram(inpImage):\n",
        "\n",
        "    histogram = np.sum(inpImage[inpImage.shape[0] // 2:, :], axis = 0)\n",
        "\n",
        "    midpoint = np.int(histogram.shape[0] / 2)\n",
        "    leftxBase = np.argmax(histogram[:midpoint])\n",
        "    rightxBase = np.argmax(histogram[midpoint:]) + midpoint\n",
        "\n",
        "    plt.xlabel(\"Image X Coordinates\")\n",
        "    plt.ylabel(\"Number of White Pixels\")\n",
        "\n",
        "    # Return histogram and x-coordinates of left & right lanes to calculate\n",
        "    # lane width in pixels\n",
        "    return histogram, leftxBase, rightxBase"
      ],
      "metadata": {
        "id": "tPgX-TkP9Imc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def slide_window_search(binary_warped, histogram):\n",
        "\n",
        "    # Find the start of left and right lane lines using histogram info\n",
        "    out_img = np.dstack((binary_warped, binary_warped, binary_warped)) * 255\n",
        "    midpoint = np.int(histogram.shape[0] / 2)\n",
        "    leftx_base = np.argmax(histogram[:midpoint])\n",
        "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
        "\n",
        "    # A total of 9 windows will be used\n",
        "    nwindows = 9\n",
        "    window_height = np.int(binary_warped.shape[0] / nwindows)\n",
        "    nonzero = binary_warped.nonzero()\n",
        "    nonzeroy = np.array(nonzero[0])\n",
        "    nonzerox = np.array(nonzero[1])\n",
        "    leftx_current = leftx_base\n",
        "    rightx_current = rightx_base\n",
        "    margin = 100\n",
        "    minpix = 50\n",
        "    left_lane_inds = []\n",
        "    right_lane_inds = []\n",
        "\n",
        "    #### START - Loop to iterate through windows and search for lane lines #####\n",
        "    for window in range(nwindows):\n",
        "        win_y_low = binary_warped.shape[0] - (window + 1) * window_height\n",
        "        win_y_high = binary_warped.shape[0] - window * window_height\n",
        "        win_xleft_low = leftx_current - margin\n",
        "        win_xleft_high = leftx_current + margin\n",
        "        win_xright_low = rightx_current - margin\n",
        "        win_xright_high = rightx_current + margin\n",
        "        cv2.rectangle(out_img, (win_xleft_low, win_y_low), (win_xleft_high, win_y_high),\n",
        "        (0,255,0), 2)\n",
        "        cv2.rectangle(out_img, (win_xright_low,win_y_low), (win_xright_high,win_y_high),\n",
        "        (0,255,0), 2)\n",
        "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) &\n",
        "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
        "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) &\n",
        "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
        "        left_lane_inds.append(good_left_inds)\n",
        "        right_lane_inds.append(good_right_inds)\n",
        "        if len(good_left_inds) > minpix:\n",
        "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
        "        if len(good_right_inds) > minpix:\n",
        "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
        "    #### END - Loop to iterate through windows and search for lane lines #######\n",
        "\n",
        "    left_lane_inds = np.concatenate(left_lane_inds)\n",
        "    right_lane_inds = np.concatenate(right_lane_inds)\n",
        "\n",
        "    leftx = nonzerox[left_lane_inds]\n",
        "    lefty = nonzeroy[left_lane_inds]\n",
        "    rightx = nonzerox[right_lane_inds]\n",
        "    righty = nonzeroy[right_lane_inds]\n",
        "\n",
        "    # Apply 2nd degree polynomial fit to fit curves\n",
        "    left_fit = np.polyfit(lefty, leftx, 2)\n",
        "    right_fit = np.polyfit(righty, rightx, 2)\n",
        "\n",
        "\n",
        "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0])\n",
        "    left_fitx = left_fit[0] * ploty**2 + left_fit[1] * ploty + left_fit[2]\n",
        "    right_fitx = right_fit[0] * ploty**2 + right_fit[1] * ploty + right_fit[2]\n",
        "\n",
        "    ltx = np.trunc(left_fitx)\n",
        "    rtx = np.trunc(right_fitx)\n",
        "    plt.plot(right_fitx)\n",
        "    # plt.show()\n",
        "\n",
        "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
        "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
        "\n",
        "    # plt.imshow(out_img)\n",
        "    plt.plot(left_fitx,  ploty, color = 'yellow')\n",
        "    plt.plot(right_fitx, ploty, color = 'yellow')\n",
        "    plt.xlim(0, 1280)\n",
        "    plt.ylim(720, 0)\n",
        "\n",
        "    return ploty, left_fit, right_fit, ltx, rtx"
      ],
      "metadata": {
        "id": "hcO184uU9LyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def general_search(binary_warped, left_fit, right_fit):\n",
        "\n",
        "    nonzero = binary_warped.nonzero()\n",
        "    nonzeroy = np.array(nonzero[0])\n",
        "    nonzerox = np.array(nonzero[1])\n",
        "    margin = 100\n",
        "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy +\n",
        "    left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) +\n",
        "    left_fit[1]*nonzeroy + left_fit[2] + margin)))\n",
        "\n",
        "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy +\n",
        "    right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) +\n",
        "    right_fit[1]*nonzeroy + right_fit[2] + margin)))\n",
        "\n",
        "    leftx = nonzerox[left_lane_inds]\n",
        "    lefty = nonzeroy[left_lane_inds]\n",
        "    rightx = nonzerox[right_lane_inds]\n",
        "    righty = nonzeroy[right_lane_inds]\n",
        "    left_fit = np.polyfit(lefty, leftx, 2)\n",
        "    right_fit = np.polyfit(righty, rightx, 2)\n",
        "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0])\n",
        "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
        "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
        "\n",
        "\n",
        "    ## VISUALIZATION ###########################################################\n",
        "\n",
        "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
        "    window_img = np.zeros_like(out_img)\n",
        "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
        "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
        "\n",
        "    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
        "    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin,\n",
        "                                  ploty])))])\n",
        "    left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
        "    right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
        "    right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, ploty])))])\n",
        "    right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
        "\n",
        "    cv2.fillPoly(window_img, np.int_([left_line_pts]), (0, 255, 0))\n",
        "    cv2.fillPoly(window_img, np.int_([right_line_pts]), (0, 255, 0))\n",
        "    result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
        "\n",
        "    # plt.imshow(result)\n",
        "    plt.plot(left_fitx,  ploty, color = 'yellow')\n",
        "    plt.plot(right_fitx, ploty, color = 'yellow')\n",
        "    plt.xlim(0, 1280)\n",
        "    plt.ylim(720, 0)\n",
        "\n",
        "    ret = {}\n",
        "    ret['leftx'] = leftx\n",
        "    ret['rightx'] = rightx\n",
        "    ret['left_fitx'] = left_fitx\n",
        "    ret['right_fitx'] = right_fitx\n",
        "    ret['ploty'] = ploty\n",
        "\n",
        "    return ret"
      ],
      "metadata": {
        "id": "cPFyIhel9SAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def measure_lane_curvature(ploty, leftx, rightx):\n",
        "\n",
        "    leftx = leftx[::-1]  # Reverse to match top-to-bottom in y\n",
        "    rightx = rightx[::-1]  # Reverse to match top-to-bottom in y\n",
        "\n",
        "    # Choose the maximum y-value, corresponding to the bottom of the image\n",
        "    y_eval = np.max(ploty)\n",
        "\n",
        "    # Fit new polynomials to x, y in world space\n",
        "    left_fit_cr = np.polyfit(ploty*ym_per_pix, leftx*xm_per_pix, 2)\n",
        "    right_fit_cr = np.polyfit(ploty*ym_per_pix, rightx*xm_per_pix, 2)\n",
        "\n",
        "    # Calculate the new radii of curvature\n",
        "    left_curverad  = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
        "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
        "    # Now our radius of curvature is in meters\n",
        "    # print(left_curverad, 'm', right_curverad, 'm')\n",
        "\n",
        "    # Decide if it is a left or a right curve\n",
        "    if leftx[0] - leftx[-1] > 60:\n",
        "        curve_direction = 'Left Curve'\n",
        "    elif leftx[-1] - leftx[0] > 60:\n",
        "        curve_direction = 'Right Curve'\n",
        "    else:\n",
        "        curve_direction = 'Straight'\n",
        "\n",
        "    return (left_curverad + right_curverad) / 2.0, curve_direction"
      ],
      "metadata": {
        "id": "dDDw_AWS9V9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_lane_lines(original_image, warped_image, Minv, draw_info):\n",
        "\n",
        "    leftx = draw_info['leftx']\n",
        "    rightx = draw_info['rightx']\n",
        "    left_fitx = draw_info['left_fitx']\n",
        "    right_fitx = draw_info['right_fitx']\n",
        "    ploty = draw_info['ploty']\n",
        "\n",
        "    warp_zero = np.zeros_like(warped_image).astype(np.uint8)\n",
        "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
        "\n",
        "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
        "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
        "    pts = np.hstack((pts_left, pts_right))\n",
        "\n",
        "    mean_x = np.mean((left_fitx, right_fitx), axis=0)\n",
        "    pts_mean = np.array([np.flipud(np.transpose(np.vstack([mean_x, ploty])))])\n",
        "\n",
        "    cv2.fillPoly(color_warp, np.int_([pts]), (0, 255, 0))\n",
        "    cv2.fillPoly(color_warp, np.int_([pts_mean]), (0, 255, 255))\n",
        "\n",
        "    newwarp = cv2.warpPerspective(color_warp, Minv, (original_image.shape[1], original_image.shape[0]))\n",
        "    result = cv2.addWeighted(original_image, 1, newwarp, 0.3, 0)\n",
        "\n",
        "    return pts_mean, result"
      ],
      "metadata": {
        "id": "4bzFA22d9Y3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def offCenter(meanPts, inpFrame):\n",
        "\n",
        "    # Calculating deviation in meters\n",
        "    mpts = meanPts[-1][-1][-2].astype(int)\n",
        "    pixelDeviation = inpFrame.shape[1] / 2 - abs(mpts)\n",
        "    deviation = pixelDeviation * xm_per_pix\n",
        "    direction = \"left\" if deviation < 0 else \"right\"\n",
        "\n",
        "    return deviation, direction"
      ],
      "metadata": {
        "id": "lD0LxK9U9cdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def addText(img, radius, direction, deviation, devDirection):\n",
        "\n",
        "    # Add the radius and center position to the image\n",
        "    font = cv2.FONT_HERSHEY_TRIPLEX\n",
        "\n",
        "    if (direction != 'Straight'):\n",
        "        text = 'Radius of Curvature: ' + '{:04.0f}'.format(radius) + 'm'\n",
        "        text1 = 'Curve Direction: ' + (direction)\n",
        "\n",
        "    else:\n",
        "        text = 'Radius of Curvature: ' + 'N/A'\n",
        "        text1 = 'Curve Direction: ' + (direction)\n",
        "\n",
        "    cv2.putText(img, text , (50,100), font, 0.8, (0,100, 200), 2, cv2.LINE_AA)\n",
        "    cv2.putText(img, text1, (50,150), font, 0.8, (0,100, 200), 2, cv2.LINE_AA)\n",
        "\n",
        "    # Deviation\n",
        "    deviation_text = 'Off Center: ' + str(round(abs(deviation), 3)) + 'm' + ' to the ' + devDirection\n",
        "    cv2.putText(img, deviation_text, (50, 200), cv2.FONT_HERSHEY_TRIPLEX, 0.8, (0,100, 200), 2, cv2.LINE_AA)\n",
        "\n",
        "    return img"
      ],
      "metadata": {
        "id": "5aJM4OuI9etR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = readVideo()"
      ],
      "metadata": {
        "id": "1xbmdp8y9hZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython import display\n",
        "\n",
        "while True:\n",
        "\n",
        "    _, frame = image.read()\n",
        "\n",
        "\n",
        "    # Apply perspective warping by calling the \"perspectiveWarp()\" function\n",
        "    # Then assign it to the variable called (birdView)\n",
        "    # Provide this function with:\n",
        "    # 1- an image to apply perspective warping (frame)\n",
        "    birdView, birdViewL, birdViewR, minverse = perspectiveWarp(frame)\n",
        "\n",
        "\n",
        "    # Apply image processing by calling the \"processImage()\" function\n",
        "    # Then assign their respective variables (img, hls, grayscale, thresh, blur, canny)\n",
        "    # Provide this function with:\n",
        "    # 1- an already perspective warped image to process (birdView)\n",
        "    img, hls, grayscale, thresh, blur, canny = processImage(birdView)\n",
        "    imgL, hlsL, grayscaleL, threshL, blurL, cannyL = processImage(birdViewL)\n",
        "    imgR, hlsR, grayscaleR, threshR, blurR, cannyR = processImage(birdViewR)\n",
        "\n",
        "\n",
        "    # Plot and display the histogram by calling the \"get_histogram()\" function\n",
        "    # Provide this function with:\n",
        "    # 1- an image to calculate histogram on (thresh)\n",
        "    hist, leftBase, rightBase = plotHistogram(thresh)\n",
        "    # print(rightBase - leftBase)\n",
        "    plt.plot(hist)\n",
        "    # plt.show()\n",
        "\n",
        "\n",
        "    ploty, left_fit, right_fit, left_fitx, right_fitx = slide_window_search(thresh, hist)\n",
        "    plt.plot(left_fit)\n",
        "    # plt.show()\n",
        "\n",
        "\n",
        "    draw_info = general_search(thresh, left_fit, right_fit)\n",
        "    # plt.show()\n",
        "\n",
        "\n",
        "    curveRad, curveDir = measure_lane_curvature(ploty, left_fitx, right_fitx)\n",
        "\n",
        "\n",
        "    # Filling the area of detected lanes with green\n",
        "    meanPts, result = draw_lane_lines(frame, thresh, minverse, draw_info)\n",
        "\n",
        "\n",
        "    deviation, directionDev = offCenter(meanPts, frame)\n",
        "\n",
        "\n",
        "    # Adding text to our final image\n",
        "    finalImg = addText(result, curveRad, curveDir, deviation, directionDev)\n",
        "\n",
        "    rgb_img = cv2.cvtColor(finalImg, cv2.COLOR_BGR2RGB)\t\t# this converts it into RGB\n",
        "    \n",
        "    display.clear_output(wait=True)\n",
        "    plt.clf()\n",
        "    plt.imshow(finalImg)\n",
        "    plt.pause(0.02)\n",
        "\n",
        "    #plt.show()\n",
        "    # Displaying final image\n",
        "    #cv2.imshow(\"Final\", finalImg)\n",
        "\n",
        "\n",
        "    # Wait for the ENTER key to be pressed to stop playback\n",
        "    if cv2.waitKey(1) == 13:\n",
        "        break\n",
        "\n",
        "#### END - LOOP TO PLAY THE INPUT IMAGE ########################################\n",
        "################################################################################\n",
        "\n",
        "# Cleanup\n",
        "image.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "wH7q0O9l9lOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lBlWjpgs9xss"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}